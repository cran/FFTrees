---
title: "simfft()"
author: "Nathaniel Phillips"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Simulating FFTs with simfft()}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


```{r, echo = F, message = F, results = 'hide'}
library(FFTrees)
```

This function simulates multiple cross-validations of data with the `fft()` function.

## Example with breastcancer

Let's start with an example, we'll create FFTs fitted to the `breastcancer` dataset. Here's how the dataset looks:

```{r}
head(breastcancer)
```

We'll create a new fft object called `heart.fft` using the `fft()` function. We'll set the criterion to `breastcancer$diagnosis == "M"` and use all other columns (`breastcancer[,names(breastcancer) != "diagnosis"]` as potential predictors. Additionally, we'll define two parameters:

- `train.p = .1`: Train the trees on a random sample of 10% of the original training dataset, and test the trees on the remaining 50%
- `sim.n = 10`: Do 10 simulations

```{r, results = 'hide'}
set.seed(100) # For reproducability

bcancer.fft.sim <- simfft(
  train.cue.df = breastcancer[,names(breastcancer) != "diagnosis"],
  train.criterion.v =  breastcancer$diagnosis == "M",
  train.p = .1,
  sim.n = 10
)
```

## Results

The function will return a dataframe with fitting and test results for each simulation:

```{r}
bcancer.fft.sim
```

## Plotting the results

You can plot the results using the `simfftplot()` function. 

### Which cues were selected the most often?

If you set `roc = F` you'll see a bar chart showing how often each of the possible cues was used in trees. This gives you an indication of how important each cue is. For example, if a cue is used in >95% of simulations, this suggests that the cue is a consistently good predictor of the criterion across a wide range of training samples.

```{r, fig.width = 5, fig.height = 5}
simfftplot(bcancer.fft.sim,
           roc = F
           )
```

### How well (and consistently) did the trees perform?

If you set `roc = T`, you'll see a distribution of hit-rates and false-alarm rates for trees across all simulations. You can also specify which data (training or test) to display with `which.data`.

Here, we can see the distribution of HR and FAR for the training data:

```{r, fig.width = 5, fig.height = 5}
simfftplot(bcancer.fft.sim,
           roc = T,
           which.data = "train"
           )
```

Now let's do the testing data. We should expect the trees to do a bit worse here:

```{r, fig.width = 5, fig.height = 5}
simfftplot(bcancer.fft.sim,
           roc = T,
           which.data = "test"
           )
```

To add curves for CART and Logistic Regression by including the arguments `lr = T` and `cart = T`. Let's look at the performance of CART and LR compared to the trees for the training data:

```{r, fig.width = 5, fig.height = 5}
simfftplot(bcancer.fft.sim,
           roc = T,
           lr = T,
           cart = T,
           which.data = "train"
           )
```

It looks like LR dominated both CART and FFTs for the training data (in fact, for this simulation, LR always gave a perfect fit). Now let's look at the test data:

```{r, fig.width = 5, fig.height = 5}
simfftplot(bcancer.fft.sim,
           roc = T,
           lr = T,
           cart = T,
           which.data = "test"
           )
```

Here, we can see that for the testing data, all three algorithms performed similarly well.
